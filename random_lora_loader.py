"""
RandomLoRALoader - ComfyUI Custom Node V1

ã€ä»•æ§˜æ¦‚è¦ã€‘
æŒ‡å®šã—ãŸ3ã¤ã®ãƒ•ã‚©ãƒ«ãƒ€å†…ã®LoRAã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã—ã€MODELã¨CLIPã«é©ç”¨ã™ã‚‹ãƒãƒ¼ãƒ‰

ã€å…¥åŠ›ã€‘
- MODEL: ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«
- CLIP: ãƒ™ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼

ã€å‡ºåŠ›ã€‘
- MODEL: LoRAé©ç”¨å¾Œã®ãƒ¢ãƒ‡ãƒ«
- CLIP: LoRAé©ç”¨å¾Œã®CLIP
- positive_text: é©ç”¨ã—ãŸLoRAæƒ…å ±ã¨ãƒˆãƒªã‚¬ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆpositiveç¢ºèªç”¨ï¼‰
  å½¢å¼: è¿½åŠ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆ1è¡Œç›®ï¼‰+ å„LoRAæƒ…å ±ï¼ˆæ”¹è¡ŒåŒºåˆ‡ã‚Šï¼‰
- negative_text: negativeãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆjson_sample_prompté¸æŠæ™‚ã®ã¿ï¼‰
- CONDITIONING (positive): è¿½åŠ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ+ãƒˆãƒªã‚¬ãƒ¼ãƒ¯ãƒ¼ãƒ‰é©ç”¨å¾Œã®conditioning
- CONDITIONING (negative): ä½œä¾‹å–å¾—æ™‚ã®negativeãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ

ã€è¨­å®šé …ç›®ã€‘ï¼ˆè¡¨ç¤ºé †ï¼‰
1. token_normalization: none/mean/length/length+meanï¼ˆå…±é€šï¼‰
2. weight_interpretation: comfy/A1111/compel/comfy++/down_weightï¼ˆå…±é€šï¼‰
3. additional_prompt: è¿½åŠ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆãƒˆãƒªã‚¬ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨çµåˆã—ã¦CONDITIONINGã«é©ç”¨ï¼‰ï¼ˆå…±é€šï¼‰
4-8. ã‚°ãƒ«ãƒ¼ãƒ—1è¨­å®šï¼ˆä¾‹ï¼šstyleç”¨ï¼‰
   - lora_folder_path_1: LoRAãƒ•ã‚©ãƒ«ãƒ€ã®çµ¶å¯¾ãƒ‘ã‚¹
   - include_subfolders_1: ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’å«ã‚ã‚‹ã‹
   - model_strength_1: MODELé©ç”¨å¼·åº¦
   - clip_strength_1: CLIPé©ç”¨å¼·åº¦
   - num_loras_1: é¸æŠã™ã‚‹LoRAå€‹æ•°
9-13. ã‚°ãƒ«ãƒ¼ãƒ—2è¨­å®šï¼ˆä¾‹ï¼šcharacterç”¨ï¼‰
   - lora_folder_path_2: LoRAãƒ•ã‚©ãƒ«ãƒ€ã®çµ¶å¯¾ãƒ‘ã‚¹
   - include_subfolders_2: ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’å«ã‚ã‚‹ã‹
   - model_strength_2: MODELé©ç”¨å¼·åº¦
   - clip_strength_2: CLIPé©ç”¨å¼·åº¦
   - num_loras_2: é¸æŠã™ã‚‹LoRAå€‹æ•°
14-18. ã‚°ãƒ«ãƒ¼ãƒ—3è¨­å®šï¼ˆä¾‹ï¼šconceptç”¨ï¼‰
   - lora_folder_path_3: LoRAãƒ•ã‚©ãƒ«ãƒ€ã®çµ¶å¯¾ãƒ‘ã‚¹
   - include_subfolders_3: ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’å«ã‚ã‚‹ã‹
   - model_strength_3: MODELé©ç”¨å¼·åº¦
   - clip_strength_3: CLIPé©ç”¨å¼·åº¦
   - num_loras_3: é¸æŠã™ã‚‹LoRAå€‹æ•°
19. trigger_word_source: json_combined/json_random/json_sample_prompt/metadataï¼ˆå…±é€šï¼‰
20. seed: ãƒ©ãƒ³ãƒ€ãƒ é¸æŠã®ã‚·ãƒ¼ãƒ‰å€¤ï¼ˆå…±é€šã€ComfyUIæ¨™æº–ã®control_before_generateã§åˆ¶å¾¡ï¼‰

ã€ãã®ä»–ä»•æ§˜ã€‘
- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿å–ã‚Šå„ªå…ˆé †ä½:
  1. {LoRAãƒ•ã‚¡ã‚¤ãƒ«å}.metadata.json (ComfyUI Lora Manager)
  2. {LoRAãƒ•ã‚¡ã‚¤ãƒ«å}.info (Civitai Helper)
  3. LoRAæœ¬ä½“ãƒ•ã‚¡ã‚¤ãƒ«ã®åŸ‹ã‚è¾¼ã¿ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
- trigger_word_source="metadata"æ™‚ã¯åŸ‹ã‚è¾¼ã¿ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å‚ç…§
- åŒã˜LoRAã®é‡è¤‡é¸æŠãªã—ï¼ˆä¸è¶³æ™‚ã¯å†é¸æŠã§åŸ‹ã‚ã‚‹ï¼‰
- json_sample_prompté¸æŠæ™‚ã¯positive/negativeã‚’åˆ†é›¢
- ä½œä¾‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…ã®LoRAè¨˜è¿°ï¼ˆ<lora:xxx:x.x>ï¼‰ã¯å‰Šé™¤
- LoRAé©ç”¨ã¯positiveã®ã¿
- ç©ºã®ãƒ•ã‚©ãƒ«ãƒ€æŒ‡å®šã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆã‚¨ãƒ©ãƒ¼ãªã—ï¼‰
- å…¨ã‚°ãƒ«ãƒ¼ãƒ—ç©ºã§ã‚‚ã‚¨ãƒ©ãƒ¼ãªã—ï¼ˆç©ºãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›ï¼‰
"""

import os
import json
import random
import glob
import re
from pathlib import Path
import folder_paths
import comfy.sd
import comfy.utils

# LoRAåŸ‹ã‚è¾¼ã¿ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ç”¨
try:
    from safetensors.torch import safe_open
    SAFETENSORS_AVAILABLE = True
except ImportError:
    SAFETENSORS_AVAILABLE = False
    print("[RandomLoRALoader] safetensors not available, embedded metadata reading disabled")

class RandomLoRALoader:
    """ãƒ©ãƒ³ãƒ€ãƒ LoRAé¸æŠãƒ»é©ç”¨ãƒãƒ¼ãƒ‰ï¼ˆ3ã‚°ãƒ«ãƒ¼ãƒ—å¯¾å¿œï¼‰"""
    
    # ã‚¯ãƒ©ã‚¹å¤‰æ•°ï¼ˆopencvè­¦å‘Šè¡¨ç¤ºãƒ•ãƒ©ã‚°ï¼‰
    _opencv_warning_shown = False
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "model": ("MODEL",),
                "clip": ("CLIP",),
                "token_normalization": (
                    ["none", "mean", "length", "length+mean"],
                    {
                        "default": "none"
                    }
                ),
                "weight_interpretation": (
                    ["comfy", "A1111", "compel", "comfy++", "down_weight"],
                    {
                        "default": "A1111"
                    }
                ),
                "additional_prompt_positive": ("STRING", {
                    "default": "",
                    "multiline": True,
                    "placeholder": "Additional positive prompt"
                }),
                "additional_prompt_negative": ("STRING", {
                    "default": "",
                    "multiline": True,
                    "placeholder": "Additional negative prompt"
                }),
                # ã‚°ãƒ«ãƒ¼ãƒ—1
                "lora_folder_path_1": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "placeholder": "Group 1 LoRA folder path (e.g., style)"
                }),
                "include_subfolders_1": ("BOOLEAN", {
                    "default": True
                }),
                "unique_by_filename_1": ("BOOLEAN", {
                    "default": True,
                    "label": "Unique by filename (exclude duplicates)"
                }),
                "model_strength_1": ("STRING", {
                    "default": "1.0",
                    "multiline": False,
                    "placeholder": "e.g., 1.0 or 0.4-0.8"
                }),
                "clip_strength_1": ("STRING", {
                    "default": "1.0",
                    "multiline": False,
                    "placeholder": "e.g., 1.0 or 0.4-0.8"
                }),
                "num_loras_1": ("INT", {
                    "default": 1,
                    "min": 0,
                    "max": 20,
                    "step": 1,
                    "display": "number"
                }),
                # ã‚°ãƒ«ãƒ¼ãƒ—2
                "lora_folder_path_2": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "placeholder": "Group 2 LoRA folder path (e.g., character)"
                }),
                "include_subfolders_2": ("BOOLEAN", {
                    "default": True
                }),
                "unique_by_filename_2": ("BOOLEAN", {
                    "default": True,
                    "label": "Unique by filename (exclude duplicates)"
                }),
                "model_strength_2": ("STRING", {
                    "default": "1.0",
                    "multiline": False,
                    "placeholder": "e.g., 1.0 or 0.4-0.8"
                }),
                "clip_strength_2": ("STRING", {
                    "default": "1.0",
                    "multiline": False,
                    "placeholder": "e.g., 1.0 or 0.4-0.8"
                }),
                "num_loras_2": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 20,
                    "step": 1,
                    "display": "number"
                }),
                # ã‚°ãƒ«ãƒ¼ãƒ—3
                "lora_folder_path_3": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "placeholder": "Group 3 LoRA folder path (e.g., concept)"
                }),
                "include_subfolders_3": ("BOOLEAN", {
                    "default": True
                }),
                "unique_by_filename_3": ("BOOLEAN", {
                    "default": True,
                    "label": "Unique by filename (exclude duplicates)"
                }),
                "model_strength_3": ("STRING", {
                    "default": "1.0",
                    "multiline": False,
                    "placeholder": "e.g., 1.0 or 0.4-0.8"
                }),
                "clip_strength_3": ("STRING", {
                    "default": "1.0",
                    "multiline": False,
                    "placeholder": "e.g., 1.0 or 0.4-0.8"
                }),
                "num_loras_3": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 20,
                    "step": 1,
                    "display": "number"
                }),
                # å…±é€šè¨­å®š
                "trigger_word_source": (
                    ["json_combined", "json_random", "json_sample_prompt", "metadata"],
                    {
                        "default": "json_combined"
                    }
                ),
                "seed": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 0xffffffffffffffff,
                    "step": 1,
                    "display": "number"
                }),
            }
        }
    
    RETURN_TYPES = ("MODEL", "CLIP", "STRING", "STRING", "CONDITIONING", "CONDITIONING", "IMAGE")
    RETURN_NAMES = ("MODEL", "CLIP", "positive_text", "negative_text", "positive", "negative", "preview")
    FUNCTION = "load_random_loras"
    CATEGORY = "loaders"
    
    def _find_lora_files(self, folder_path, include_subfolders):
        """
        æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€å†…ã®LoRAãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.safetensorsï¼‰ã‚’æ¤œç´¢
        
        Args:
            folder_path: æ¤œç´¢å¯¾è±¡ãƒ•ã‚©ãƒ«ãƒ€ã®çµ¶å¯¾ãƒ‘ã‚¹
            include_subfolders: ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’å«ã‚ã‚‹ã‹
        
        Returns:
            list: LoRAãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
        """
        if not os.path.exists(folder_path):
            print(f"[RandomLoRALoader] ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {folder_path}")
            return []
        
        pattern = "**/*.safetensors" if include_subfolders else "*.safetensors"
        lora_files = glob.glob(os.path.join(folder_path, pattern), recursive=include_subfolders)
        
        print(f"[RandomLoRALoader] æ¤œå‡ºã•ã‚ŒãŸLoRAæ•°: {len(lora_files)}")
        return lora_files
    
    def _select_random_loras(self, lora_files, num_loras, seed):
        """
        LoRAãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠï¼ˆé‡è¤‡ãªã—ã€ä¸è¶³æ™‚ã¯å†é¸æŠï¼‰
        
        Args:
            lora_files: LoRAãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
            num_loras: é¸æŠã™ã‚‹å€‹æ•°
            seed: ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰
        
        Returns:
            list: é¸æŠã•ã‚ŒãŸLoRAãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
        """
        if not lora_files:
            return []
        
        random.seed(seed)
        
        # é‡è¤‡ãªã—ã§é¸æŠã§ãã‚‹æœ€å¤§æ•°
        available_count = len(lora_files)
        
        if num_loras <= available_count:
            # ååˆ†ãªæ•°ãŒã‚ã‚‹å ´åˆã¯é‡è¤‡ãªã—ã§é¸æŠ
            return random.sample(lora_files, num_loras)
        else:
            # ä¸è¶³ã™ã‚‹å ´åˆã¯å…¨ã¦é¸æŠå¾Œã€å†é¸æŠã§åŸ‹ã‚ã‚‹
            selected = lora_files.copy()
            remaining = num_loras - available_count
            
            # ä¸è¶³åˆ†ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«è¿½åŠ 
            for _ in range(remaining):
                selected.append(random.choice(lora_files))
            
            # æœ€çµ‚çš„ã«ã‚·ãƒ£ãƒƒãƒ•ãƒ«
            random.shuffle(selected)
            return selected
    
    def _unique_by_filename(self, lora_files, group_name=""):
        """
        ãƒ•ã‚¡ã‚¤ãƒ«åã§ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–ï¼ˆé‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«åã‚’é™¤å¤–ï¼‰
        
        Args:
            lora_files: LoRAãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
            group_name: ã‚°ãƒ«ãƒ¼ãƒ—åï¼ˆãƒ­ã‚°ç”¨ï¼‰
        
        Returns:
            list: ãƒ•ã‚¡ã‚¤ãƒ«åãŒãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
        """
        seen_names = {}
        unique_files = []
        
        for file_path in lora_files:
            filename = os.path.basename(file_path)
            
            if filename not in seen_names:
                seen_names[filename] = file_path
                unique_files.append(file_path)
            else:
                # é‡è¤‡æ¤œå‡ºæ™‚ã¯ãƒ­ã‚°å‡ºåŠ›
                print(f"[RandomLoRALoader] {group_name}: Duplicate filename detected: {filename}")
                print(f"  Keeping: {seen_names[filename]}")
                print(f"  Skipping: {file_path}")
        
        return unique_files
    
    def _parse_strength(self, strength_str):
        """
        å¼·åº¦æ–‡å­—åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦å€¤ã‚’è¿”ã™
        
        å¯¾å¿œå½¢å¼:
        - "1.0" â†’ 1.0ï¼ˆãã®ã¾ã¾ï¼‰
        - "0.55" â†’ 0.55ï¼ˆãã®ã¾ã¾ï¼‰
        - "0.4-0.8" â†’ 0.4, 0.5, 0.6, 0.7, 0.8ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ï¼ˆ0.1åˆ»ã¿ï¼‰
        - "0.44-0.82" â†’ 0.4, 0.5, 0.6, 0.7, 0.8ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ï¼ˆç¯„å›²ã‚’1æ¡ã«ä¸¸ã‚ã‚‹ï¼‰
        - "-0.8--0.3" â†’ -0.8, -0.7, -0.6, ..., -0.3ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ï¼ˆãƒã‚¤ãƒŠã‚¹ç¯„å›²å¯¾å¿œï¼‰
        
        Args:
            strength_str: å¼·åº¦æ–‡å­—åˆ—
        
        Returns:
            float: å®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹å¼·åº¦å€¤
        """
        import re
        strength_str = str(strength_str).strip()
        
        # ç¯„å›²æŒ‡å®šã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒï¼ˆãƒã‚¤ãƒŠã‚¹å€¤å¯¾å¿œï¼‰
        # ä¾‹: "0.6-0.9", "-0.8--0.3", "-0.5-0.5", "0.3--0.7"
        range_pattern = r'^(-?\d+\.?\d*)\s*-\s*(-?\d+\.?\d*)$'
        match = re.match(range_pattern, strength_str)
        
        if match:
            try:
                # ç¯„å›²ã®ä¸Šé™ä¸‹é™ã‚’1æ¡ã«ä¸¸ã‚ã‚‹
                min_val = round(float(match.group(1)), 1)
                max_val = round(float(match.group(2)), 1)
                
                # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
                if min_val < -10.0 or max_val > 10.0:
                    raise ValueError("å¼·åº¦ã¯ -10.0 ã€œ 10.0 ã®ç¯„å›²ã§æŒ‡å®šã—ã¦ãã ã•ã„")
                if min_val > max_val:
                    raise ValueError("æœ€å°å€¤ã¯æœ€å¤§å€¤ã‚ˆã‚Šå°ã•ãã—ã¦ãã ã•ã„")
                
                # 0.1åˆ»ã¿ã®å€¤ã®ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ
                values = []
                current = min_val
                while current <= max_val + 0.01:  # æµ®å‹•å°æ•°ç‚¹èª¤å·®å¯¾ç­–
                    values.append(round(current, 1))
                    current += 0.1
                
                # å¿µã®ãŸã‚ç©ºãƒªã‚¹ãƒˆãƒã‚§ãƒƒã‚¯
                if not values:
                    print(f"[RandomLoRALoader] âŒ ç¯„å›²æŒ‡å®šã‚¨ãƒ©ãƒ¼ã€1.0ã‚’ä½¿ç”¨")
                    return 1.0
                
                # ãƒ©ãƒ³ãƒ€ãƒ ã«1ã¤é¸æŠ
                selected = random.choice(values)
                print(f"[RandomLoRALoader] å¼·åº¦ç¯„å›² {min_val}-{max_val} ã‹ã‚‰ {selected} ã‚’é¸æŠ")
                return selected
                
            except ValueError as e:
                print(f"[RandomLoRALoader] âŒ å¼·åº¦ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
                print(f"[RandomLoRALoader] ğŸ’¡ ä½¿ç”¨ä¾‹: '1.0' ã¾ãŸã¯ '0.4-0.8'")
                return 1.0
            except Exception as e:
                print(f"[RandomLoRALoader] âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
                return 1.0
        else:
            # é€šå¸¸ã®æ•°å€¤ï¼ˆãã®ã¾ã¾ä½¿ç”¨ï¼‰
            try:
                value = float(strength_str)
                if value < -10.0 or value > 10.0:
                    print(f"[RandomLoRALoader] âŒ å¼·åº¦ {value} ã¯ç¯„å›²å¤–ã€1.0ã‚’ä½¿ç”¨")
                    return 1.0
                return value
            except:
                print(f"[RandomLoRALoader] âŒ å¼·åº¦ '{strength_str}' ã‚’è§£æã§ãã¾ã›ã‚“ã€1.0ã‚’ä½¿ç”¨")
                print(f"[RandomLoRALoader] ğŸ’¡ ä½¿ç”¨ä¾‹: '1.0' ã¾ãŸã¯ '0.4-0.8'")
                return 1.0
    
    def _load_json_metadata(self, lora_path):
        """
        å¤–éƒ¨JSONãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯LoRAåŸ‹ã‚è¾¼ã¿ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
        
        å„ªå…ˆé †ä½:
        1. {filename}.metadata.json (ComfyUI Lora Managerå½¢å¼)
        2. {filename}.info (Civitai Helperå½¢å¼)
        3. LoRAæœ¬ä½“ãƒ•ã‚¡ã‚¤ãƒ«ã®åŸ‹ã‚è¾¼ã¿ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        
        Args:
            lora_path: LoRAãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (.safetensors)
        
        Returns:
            dict: JSONãƒ‡ãƒ¼ã‚¿ï¼ˆèª­ã¿è¾¼ã¿å¤±æ•—æ™‚ã¯Noneï¼‰
        """
        # .safetensorsã‚’é™¤ã„ãŸãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—
        base_name = os.path.splitext(lora_path)[0]
        
        # å„ªå…ˆé †ä½1: .metadata.json (ComfyUI Lora Manager)
        json_path_metadata = f"{base_name}.metadata.json"
        if os.path.exists(json_path_metadata):
            try:
                with open(json_path_metadata, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"[RandomLoRALoader] JSONèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({json_path_metadata}): {e}")
        
        # å„ªå…ˆé †ä½2: .info (Civitai Helper)
        json_path_info = f"{base_name}.info"
        if os.path.exists(json_path_info):
            try:
                with open(json_path_info, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"[RandomLoRALoader] JSONèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({json_path_info}): {e}")
        
        # å„ªå…ˆé †ä½3: LoRAæœ¬ä½“ãƒ•ã‚¡ã‚¤ãƒ«ã®åŸ‹ã‚è¾¼ã¿ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        embedded_data = self._load_embedded_metadata(lora_path)
        if embedded_data:
            return embedded_data
        
        # ã©ã‚Œã‚‚è¦‹ã¤ã‹ã‚‰ãªã„
        print(f"[RandomLoRALoader] ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {base_name}")
        return None
    
    def _load_embedded_metadata(self, lora_path):
        """
        LoRAæœ¬ä½“ãƒ•ã‚¡ã‚¤ãƒ«ã®åŸ‹ã‚è¾¼ã¿ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
        
        Args:
            lora_path: LoRAãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (.safetensors)
        
        Returns:
            dict: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆèª­ã¿è¾¼ã¿å¤±æ•—æ™‚ã¯Noneï¼‰
        """
        if not SAFETENSORS_AVAILABLE:
            return None
        
        if not os.path.exists(lora_path):
            return None
        
        try:
            with safe_open(lora_path, framework="pt", device="cpu") as f:
                metadata = f.metadata()
                
                if not metadata:
                    return None
                
                # ss_tag_frequencyï¼ˆkohya_sså½¢å¼ï¼‰ã‹ã‚‰ãƒˆãƒªã‚¬ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
                if "ss_tag_frequency" in metadata:
                    tag_freq_str = metadata.get("ss_tag_frequency", "{}")
                    try:
                        tag_freq = json.loads(tag_freq_str)
                        # æœ€ã‚‚é »åº¦ã®é«˜ã„ã‚¿ã‚°ã‚»ãƒƒãƒˆã‚’å–å¾—
                        if tag_freq:
                            # å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚¿ã‚°ã‚’çµåˆ
                            all_tags = []
                            for dataset_tags in tag_freq.values():
                                all_tags.extend(dataset_tags.keys())
                            
                            # é‡è¤‡é™¤å»
                            unique_tags = list(dict.fromkeys(all_tags))
                            
                            # Civitaiå½¢å¼ã«å¤‰æ›
                            trigger_words = ", ".join(unique_tags[:20])  # ä¸Šä½20å€‹
                            
                            return {
                                "civitai": {
                                    "trainedWords": [trigger_words]
                                }
                            }
                    except json.JSONDecodeError:
                        pass
                
                # ãã®ä»–ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰ãƒˆãƒªã‚¬ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
                if "modelspec.trigger_word" in metadata:
                    trigger = metadata["modelspec.trigger_word"]
                    return {
                        "civitai": {
                            "trainedWords": [trigger]
                        }
                    }
                
                # ss_output_nameï¼ˆãƒ¢ãƒ‡ãƒ«åï¼‰
                if "ss_output_name" in metadata:
                    output_name = metadata["ss_output_name"]
                    return {
                        "civitai": {
                            "trainedWords": [output_name]
                        }
                    }
                
                return None
                
        except Exception as e:
            print(f"[RandomLoRALoader] åŸ‹ã‚è¾¼ã¿ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({lora_path}): {e}")
            return None
    
    def _get_trigger_words_combined(self, lora_path):
        """
        JSONã‹ã‚‰å…¨ãƒˆãƒªã‚¬ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’çµåˆã—ã¦å–å¾—ï¼ˆé‡è¤‡é™¤å»ï¼‰
        
        Args:
            lora_path: LoRAãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        
        Returns:
            str: å…¨ãƒˆãƒªã‚¬ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’çµåˆã—ãŸæ–‡å­—åˆ—
        """
        json_data = self._load_json_metadata(lora_path)
        if not json_data:
            return ""
        
        # civitai.trainedWordsã‚’å–å¾—
        trained_words = json_data.get("civitai", {}).get("trainedWords", [])
        if not trained_words:
            print(f"[RandomLoRALoader] trainedWordsãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {lora_path}")
            return ""
        
        # å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’çµåˆã—ã¦é‡è¤‡é™¤å»
        all_tags = []
        for pattern in trained_words:
            tags = [tag.strip() for tag in pattern.split(',')]
            all_tags.extend(tags)
        
        # é‡è¤‡é™¤å»ï¼ˆé †åºã‚’ä¿æŒï¼‰
        unique_tags = []
        seen = set()
        for tag in all_tags:
            if tag and tag.lower() not in seen:
                unique_tags.append(tag)
                seen.add(tag.lower())
        
        return ", ".join(unique_tags)
    
    def _get_trigger_words_random(self, lora_path):
        """
        JSONã‹ã‚‰ãƒˆãƒªã‚¬ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«1ã¤é¸æŠ
        
        Args:
            lora_path: LoRAãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        
        Returns:
            str: ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã•ã‚ŒãŸãƒˆãƒªã‚¬ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³
        """
        json_data = self._load_json_metadata(lora_path)
        if not json_data:
            return ""
        
        # civitai.trainedWordsã‚’å–å¾—
        trained_words = json_data.get("civitai", {}).get("trainedWords", [])
        if not trained_words:
            print(f"[RandomLoRALoader] trainedWordsãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {lora_path}")
            return ""
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã«1ã¤é¸æŠ
        selected_pattern = random.choice(trained_words)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³å†…ã§é‡è¤‡é™¤å»
        tags = [tag.strip() for tag in selected_pattern.split(',')]
        unique_tags = []
        seen = set()
        for tag in tags:
            if tag and tag.lower() not in seen:
                unique_tags.append(tag)
                seen.add(tag.lower())
        
        return ", ".join(unique_tags)
    
    def _get_sample_prompt_from_json(self, lora_path):
        """
        JSONã‹ã‚‰ä½œä¾‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«1ã¤å–å¾—
        ä½œä¾‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…ã®LoRAè¨˜è¿°ã‚’å‰Šé™¤
        
        Args:
            lora_path: LoRAãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        
        Returns:
            tuple: (positive_prompt, negative_prompt)
        """
        json_data = self._load_json_metadata(lora_path)
        if not json_data:
            return "", ""
        
        # civitai.imagesã‚’å–å¾—
        images = json_data.get("civitai", {}).get("images", [])
        if not images:
            print(f"[RandomLoRALoader] imagesãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {lora_path}")
            return "", ""
        
        # metaã‚’æŒã¤ç”»åƒã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆmetaãŒNoneã§ãªã„ã“ã¨ã‚‚ç¢ºèªï¼‰
        valid_images = [img for img in images if "meta" in img and img["meta"] is not None]
        if not valid_images:
            print(f"[RandomLoRALoader] metaã‚’æŒã¤ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {lora_path}")
            return "", ""
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã«1ã¤é¸æŠ
        selected_image = random.choice(valid_images)
        meta = selected_image.get("meta", {})
        
        positive = meta.get("prompt", "")
        negative = meta.get("negativePrompt", "")
        
        # LoRAè¨˜è¿°ã‚’å‰Šé™¤ï¼ˆ<lora:xxx:x.x>ã¾ãŸã¯<lora:xxx:x.x:x.x>å½¢å¼ï¼‰
        lora_pattern = r'<lora:[^>]+>'
        positive = re.sub(lora_pattern, '', positive)
        negative = re.sub(lora_pattern, '', negative)
        
        # è¤‡æ•°ã®ç©ºç™½ã‚„ã‚«ãƒ³ãƒã‚’æ•´ç†
        positive = re.sub(r'\s*,\s*,+\s*', ', ', positive)  # é€£ç¶šã‚«ãƒ³ãƒã‚’1ã¤ã«
        positive = re.sub(r'^\s*,\s*|\s*,\s*$', '', positive)  # å…ˆé ­æœ«å°¾ã®ã‚«ãƒ³ãƒå‰Šé™¤
        positive = re.sub(r'\s+', ' ', positive).strip()  # è¤‡æ•°ç©ºç™½ã‚’1ã¤ã«
        
        negative = re.sub(r'\s*,\s*,+\s*', ', ', negative)
        negative = re.sub(r'^\s*,\s*|\s*,\s*$', '', negative)
        negative = re.sub(r'\s+', ' ', negative).strip()
        
        return positive, negative
    
    def _get_trigger_words_from_embedded(self, lora_path):
        """
        LoRAåŸ‹ã‚è¾¼ã¿ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç›´æ¥ãƒˆãƒªã‚¬ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—
        å¤–éƒ¨JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç„¡è¦–ã—ã¦ã€LoRAæœ¬ä½“ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’å‚ç…§
        
        Args:
            lora_path: LoRAãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        
        Returns:
            str: ãƒˆãƒªã‚¬ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        """
        embedded_data = self._load_embedded_metadata(lora_path)
        if not embedded_data:
            return ""
        
        # civitai.trainedWordsã‚’å–å¾—ï¼ˆ_load_embedded_metadataã§å¤‰æ›æ¸ˆã¿ï¼‰
        trained_words = embedded_data.get("civitai", {}).get("trainedWords", [])
        if not trained_words:
            return ""
        
        # æœ€åˆã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½¿ç”¨ï¼ˆåŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã¯é€šå¸¸1ã¤ï¼‰
        return trained_words[0] if trained_words else ""
    
    def _load_lora(self, model, clip, lora_path, model_strength, clip_strength):
        """
        LoRAã‚’MODELã¨CLIPã«é©ç”¨
        
        Args:
            model: å…¥åŠ›MODEL
            clip: å…¥åŠ›CLIP
            lora_path: LoRAãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            model_strength: MODELé©ç”¨å¼·åº¦
            clip_strength: CLIPé©ç”¨å¼·åº¦
        
        Returns:
            tuple: (é©ç”¨å¾ŒMODEL, é©ç”¨å¾ŒCLIP)
        """
        try:
            # LoRAèª­ã¿è¾¼ã¿æ™‚ã®è­¦å‘Šã‚’å®Œå…¨æŠ‘åˆ¶
            import logging
            import warnings
            import sys
            import os
            import builtins
            
            # Pythonã®è­¦å‘Šã‚’ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–
            with warnings.catch_warnings():
                warnings.filterwarnings("ignore")
                
                # å…¨ãƒ­ã‚¬ãƒ¼ã®ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’ä¸€æ™‚çš„ã«ä¸Šã’ã‚‹
                loggers_to_suppress = [
                    logging.getLogger("comfy"),
                    logging.getLogger("comfy.sd"),
                    logging.getLogger("comfy.utils"),
                    logging.getLogger(),  # rootãƒ­ã‚¬ãƒ¼
                ]
                original_levels = {}
                for logger in loggers_to_suppress:
                    original_levels[logger] = logger.level
                    logger.setLevel(logging.CRITICAL)
                
                # æ¨™æº–å‡ºåŠ›ãƒ»æ¨™æº–ã‚¨ãƒ©ãƒ¼å‡ºåŠ›ã‚’ä¸¡æ–¹ã¨ã‚‚ä¸€æ™‚çš„ã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ
                old_stdout = sys.stdout
                old_stderr = sys.stderr
                devnull = open(os.devnull, 'w')
                sys.stdout = devnull
                sys.stderr = devnull
                
                # builtins.printã‚‚ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ï¼ˆæœ€çµ‚æ‰‹æ®µï¼‰
                original_print = builtins.print
                def silent_print(*args, **kwargs):
                    # "lora key not loaded"ã‚’å«ã‚€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã ã‘æŠ‘åˆ¶
                    message = ' '.join(str(arg) for arg in args)
                    if 'lora key not loaded' not in message.lower():
                        original_print(*args, **kwargs, file=old_stdout)
                builtins.print = silent_print
                
                try:
                    lora = comfy.utils.load_torch_file(lora_path, safe_load=True)
                    
                    # MODELã«LoRAé©ç”¨
                    model_lora, _ = comfy.sd.load_lora_for_models(
                        model, None, lora, model_strength, 0
                    )
                    
                    # CLIPã«LoRAé©ç”¨
                    _, clip_lora = comfy.sd.load_lora_for_models(
                        None, clip, lora, 0, clip_strength
                    )
                    
                    return model_lora, clip_lora
                finally:
                    # ã™ã¹ã¦ã‚’å…ƒã«æˆ»ã™
                    builtins.print = original_print
                    sys.stdout = old_stdout
                    sys.stderr = old_stderr
                    devnull.close()
                    
                    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’å…ƒã«æˆ»ã™
                    for logger, level in original_levels.items():
                        logger.setLevel(level)
        
        except Exception as e:
            print(f"[RandomLoRALoader] LoRAèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({lora_path}): {e}")
            return model, clip
    
    def _remove_lora_syntax(self, text):
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰<lora:xxx:0.8>å½¢å¼ã®æ§‹æ–‡ã‚’å‰Šé™¤
        
        Args:
            text: å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        
        Returns:
            LoRAæ§‹æ–‡ã‚’å‰Šé™¤ã—ãŸãƒ†ã‚­ã‚¹ãƒˆ
        """
        if not text:
            return text
        
        # <lora:filename:strength> ã¾ãŸã¯ <lora:filename:model_str:clip_str> ã‚’å‰Šé™¤
        text = re.sub(r'<lora:[^>]+>', '', text)
        
        # é€£ç¶šã‚«ãƒ³ãƒã‚’æ•´ç†
        text = re.sub(r',\s*,', ',', text)
        
        # è¡Œé ­ãƒ»è¡Œæœ«ã®ç©ºç™½ã¨ã‚«ãƒ³ãƒã‚’å‰Šé™¤
        text = text.strip().strip(',').strip()
        
        return text
    
    def _load_preview_image_as_tensor(self, lora_path):
        """
        ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒã‚’Tensorã¨ã—ã¦èª­ã¿è¾¼ã¿ï¼ˆéƒ¨åˆ†ä¸€è‡´ã€é•·è¾º1240pxï¼‰
        
        æ¤œç´¢æ–¹æ³•:
          LoRAãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆæ‹¡å¼µå­é™¤ãï¼‰ã§å§‹ã¾ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
          å„ªå…ˆé †ä½:
            1. é™æ­¢ç”»åƒ (.png, .jpg, .jpeg, .webp)
            2. å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ« (.gif, .webp, .mp4, .webm) ã®1ãƒ•ãƒ¬ãƒ¼ãƒ ç›®
          
          ä¾‹: style_anime_v1.safetensors
            â†’ style_anime_v1.png
            â†’ style_anime_v1_preview.jpg
            â†’ style_anime_v1.gif (1ãƒ•ãƒ¬ãƒ¼ãƒ ç›®)
            â†’ style_anime_v1.mp4 (1ãƒ•ãƒ¬ãƒ¼ãƒ ç›®ã€opencv-pythonãŒå¿…è¦)
            â†’ STYLE_ANIME_V1.PNG (å¤§æ–‡å­—å°æ–‡å­—ç„¡è¦–)
        
        ãƒªã‚µã‚¤ã‚º:
          é•·è¾ºã‚’1240pxã«çµ±ä¸€ï¼ˆã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ä¿æŒï¼‰
        
        Returns:
            torch.Tensor: (H, W, C) å½¢å¼ã€è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯None
        """
        try:
            from PIL import Image
            import numpy as np
            import torch
        except ImportError:
            return None
        
        # LoRAãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆæ‹¡å¼µå­ãªã—ï¼‰
        base_name = os.path.splitext(os.path.basename(lora_path))[0]
        folder = os.path.dirname(lora_path)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ï¼ˆå„ªå…ˆé †ä½é †ï¼‰
        static_image_exts = ('.png', '.jpg', '.jpeg')
        animated_image_exts = ('.gif', '.webp')  # Pillowã§å¯¾å¿œå¯èƒ½
        video_exts = ('.mp4', '.webm', '.avi', '.mov')  # opencv-pythonå¿…è¦
        
        try:
            # åŒã˜ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            files = os.listdir(folder)
            
            # éƒ¨åˆ†ä¸€è‡´ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
            matched_files = []
            for file in files:
                if file.lower().startswith(base_name.lower()):
                    matched_files.append(file)
            
            if not matched_files:
                return None
            
            # å„ªå…ˆé †ä½ã§ã‚½ãƒ¼ãƒˆ
            def get_priority(filename):
                lower = filename.lower()
                if any(lower.endswith(ext) for ext in static_image_exts):
                    return 0  # æœ€å„ªå…ˆ
                elif any(lower.endswith(ext) for ext in animated_image_exts):
                    return 1  # æ¬¡å„ªå…ˆ
                elif any(lower.endswith(ext) for ext in video_exts):
                    return 2  # æœ€å¾Œ
                else:
                    return 999  # ãã®ä»–
            
            matched_files.sort(key=get_priority)
            
            # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è©¦ã™
            for file in matched_files:
                preview_path = os.path.join(folder, file)
                lower_file = file.lower()
                
                # é™æ­¢ç”»åƒ
                if any(lower_file.endswith(ext) for ext in static_image_exts):
                    img = self._load_static_image(preview_path)
                    if img is not None:
                        return img
                
                # ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”»åƒï¼ˆGIF/WebPï¼‰
                elif any(lower_file.endswith(ext) for ext in animated_image_exts):
                    img = self._load_animated_image_first_frame(preview_path)
                    if img is not None:
                        return img
                
                # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆopencv-pythonå¿…è¦ï¼‰
                elif any(lower_file.endswith(ext) for ext in video_exts):
                    img = self._load_video_first_frame(preview_path)
                    if img is not None:
                        return img
        
        except Exception as e:
            print(f"[RandomLoRALoader] Folder read error: {e}")
        
        return None
    
    def _load_static_image(self, image_path):
        """é™æ­¢ç”»åƒã‚’èª­ã¿è¾¼ã¿"""
        try:
            from PIL import Image
            import numpy as np
            import torch
            
            img = Image.open(image_path).convert('RGB')
            return self._resize_and_convert_image(img)
        except Exception as e:
            print(f"[RandomLoRALoader] Static image load error ({image_path}): {e}")
            return None
    
    def _load_animated_image_first_frame(self, image_path):
        """ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”»åƒï¼ˆGIF/WebPï¼‰ã®1ãƒ•ãƒ¬ãƒ¼ãƒ ç›®ã‚’èª­ã¿è¾¼ã¿"""
        try:
            from PIL import Image
            import numpy as np
            import torch
            
            img = Image.open(image_path)
            
            # 1ãƒ•ãƒ¬ãƒ¼ãƒ ç›®ã«ç§»å‹•
            if hasattr(img, 'seek'):
                img.seek(0)
            
            img = img.convert('RGB')
            return self._resize_and_convert_image(img)
        except Exception as e:
            print(f"[RandomLoRALoader] Animated image load error ({image_path}): {e}")
            return None
    
    def _load_video_first_frame(self, video_path):
        """å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®1ãƒ•ãƒ¬ãƒ¼ãƒ ç›®ã‚’èª­ã¿è¾¼ã¿ï¼ˆopencv-pythonå¿…è¦ï¼‰"""
        try:
            import cv2
            from PIL import Image
            import numpy as np
            import torch
            
            # OpenCVã§å‹•ç”»ã‚’é–‹ã
            cap = cv2.VideoCapture(video_path)
            
            if not cap.isOpened():
                return None
            
            # 1ãƒ•ãƒ¬ãƒ¼ãƒ ç›®ã‚’èª­ã¿è¾¼ã¿
            ret, frame = cap.read()
            cap.release()
            
            if not ret:
                return None
            
            # BGR â†’ RGB å¤‰æ›
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # PIL Imageã«å¤‰æ›
            img = Image.fromarray(frame_rgb)
            
            return self._resize_and_convert_image(img)
        
        except ImportError:
            # opencv-pythonãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„ï¼ˆåˆå›ã®ã¿è­¦å‘Šï¼‰
            if not RandomLoRALoader._opencv_warning_shown:
                print("=" * 60)
                print("[RandomLoRALoader] Video Preview Support")
                print("=" * 60)
                print(f"Video file detected: {os.path.basename(video_path)}")
                print("opencv-python is not installed.")
                print("")
                print("To enable video preview support, install:")
                print("  pip install opencv-python")
                print("")
                print("Static images (.png/.jpg) and animated images (.gif/.webp)")
                print("will continue to work without opencv-python.")
                print("=" * 60)
                RandomLoRALoader._opencv_warning_shown = True
            return None
        except Exception as e:
            print(f"[RandomLoRALoader] Video load error ({video_path}): {e}")
            return None
    
    def _resize_and_convert_image(self, img):
        """ç”»åƒã‚’ãƒªã‚µã‚¤ã‚ºã—ã¦Tensorã«å¤‰æ›"""
        try:
            from PIL import Image
            import numpy as np
            import torch
            
            # é•·è¾ºã‚’1240pxã«ãƒªã‚µã‚¤ã‚ºï¼ˆã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ä¿æŒï¼‰
            width, height = img.size
            max_size = 1240
            
            if max(width, height) > max_size:
                # é•·è¾ºãŒ1240pxã‚’è¶…ãˆã‚‹å ´åˆã¯ãƒªã‚µã‚¤ã‚º
                if width > height:
                    new_width = max_size
                    new_height = int(height * (max_size / width))
                else:
                    new_height = max_size
                    new_width = int(width * (max_size / height))
                
                img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
            elif max(width, height) < max_size:
                # é•·è¾ºãŒ1240pxæœªæº€ã®å ´åˆã¯æ‹¡å¤§
                if width > height:
                    new_width = max_size
                    new_height = int(height * (max_size / width))
                else:
                    new_height = max_size
                    new_width = int(width * (max_size / height))
                
                img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
            
            # numpyé…åˆ—ã«å¤‰æ› (H, W, C)
            img_array = np.array(img).astype(np.float32) / 255.0
            # TensoråŒ–
            return torch.from_numpy(img_array)
        
        except Exception as e:
            print(f"[RandomLoRALoader] Image resize/convert error: {e}")
            return None
    
    def _generate_preview_batch(self, preview_images):
        """
        ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒã®ãƒãƒƒãƒã‚’ç”Ÿæˆï¼ˆ1240pxã«çµ±ä¸€ã€ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼‰
        
        Args:
            preview_images: list of torch.Tensor (å„ã€… H, W, Cã€é•·è¾º1240px)
        
        Returns:
            torch.Tensor: (B, 1240, 1240, C) å½¢å¼
        """
        try:
            import torch
            import torch.nn.functional as F
        except ImportError:
            return None
        
        if not preview_images:
            # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒãªã— â†’ é»’ç”»åƒ1æšï¼ˆ1240x1240ï¼‰
            black_image = torch.zeros((1, 1240, 1240, 3), dtype=torch.float32)
            return black_image
        
        # å…¨ã¦1240x1240ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
        padded_images = []
        target_size = 1240
        
        for img in preview_images:
            h, w, c = img.shape
            
            # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãŒå¿…è¦ã‹ç¢ºèª
            if h == target_size and w == target_size:
                padded_images.append(img)
            else:
                # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°é‡ã‚’è¨ˆç®—ï¼ˆä¸­å¤®é…ç½®ï¼‰
                pad_h = target_size - h
                pad_w = target_size - w
                pad_top = pad_h // 2
                pad_bottom = pad_h - pad_top
                pad_left = pad_w // 2
                pad_right = pad_w - pad_left
                
                # (H, W, C) â†’ (C, H, W) ã«å¤‰æ›ã—ã¦ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
                img_chw = img.permute(2, 0, 1)  # (C, H, W)
                
                # F.pad: (left, right, top, bottom)
                padded = F.pad(img_chw, (pad_left, pad_right, pad_top, pad_bottom), value=0)
                
                # (C, H, W) â†’ (H, W, C) ã«æˆ»ã™
                padded = padded.permute(1, 2, 0)
                padded_images.append(padded)
        
        # ãƒãƒƒãƒåŒ– (B, 1240, 1240, C)
        preview_batch = torch.stack(padded_images, dim=0)
        return preview_batch
    
    def _encode_prompt(self, clip, text, token_normalization, weight_interpretation):
        """
        ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’CLIPã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦CONDITIONINGã‚’ç”Ÿæˆ
        
        Args:
            clip: CLIP
            text: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚­ã‚¹ãƒˆ
            token_normalization: none/mean/length/length+mean
            weight_interpretation: comfy/A1111/compel/comfy++/down_weight
        
        Returns:
            CONDITIONING
        """
        # CLIPã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—
        # Note: ComfyUIã®å®Ÿè£…ã«ä¾å­˜ã™ã‚‹ãŸã‚ã€å®Ÿéš›ã®APIã«åˆã‚ã›ã¦èª¿æ•´ãŒå¿…è¦
        try:
            # token_normalizationã®è¨­å®šã‚’åæ˜ 
            tokens = clip.tokenize(text)
            
            # weight_interpretationã«å¿œã˜ãŸå‡¦ç†
            # ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã¯ComfyUIã®å†…éƒ¨APIã«ä¾å­˜ï¼‰
            
            cond, pooled = clip.encode_from_tokens(tokens, return_pooled=True)
            
            return [[cond, {"pooled_output": pooled}]]
        
        except Exception as e:
            print(f"[RandomLoRALoader] ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç©ºã®CONDITIONING
            return [[clip.encode(""), {}]]
    
    def load_random_loras(
        self,
        model,
        clip,
        token_normalization,
        weight_interpretation,
        additional_prompt_positive,
        additional_prompt_negative,
        # ã‚°ãƒ«ãƒ¼ãƒ—1
        lora_folder_path_1,
        include_subfolders_1,
        unique_by_filename_1,
        model_strength_1,
        clip_strength_1,
        num_loras_1,
        # ã‚°ãƒ«ãƒ¼ãƒ—2
        lora_folder_path_2,
        include_subfolders_2,
        unique_by_filename_2,
        model_strength_2,
        clip_strength_2,
        num_loras_2,
        # ã‚°ãƒ«ãƒ¼ãƒ—3
        lora_folder_path_3,
        include_subfolders_3,
        unique_by_filename_3,
        model_strength_3,
        clip_strength_3,
        num_loras_3,
        # å…±é€š
        trigger_word_source,
        seed
    ):
        """
        ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼šãƒ©ãƒ³ãƒ€ãƒ LoRAé¸æŠãƒ»é©ç”¨ï¼ˆ3ã‚°ãƒ«ãƒ¼ãƒ—å¯¾å¿œï¼‰
        
        Returns:
            tuple: (MODEL, CLIP, positive_text_output, negative_text_output, positive_conditioning, negative_conditioning)
        """
        # seedã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆComfyUIã®control_before_generateã§åˆ¶å¾¡ã•ã‚Œã‚‹ï¼‰
        print(f"[RandomLoRALoader] ä½¿ç”¨seed: {seed}")
        
        # å…¨ãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›ç”¨ã®ãƒªã‚¹ãƒˆ
        all_text_parts = []
        
        # å…¨positive/negativeãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è“„ç©
        all_positive_parts = []
        all_negative_parts = []
        
        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒåé›†
        preview_images = []
        
        # 3ã¤ã®ã‚°ãƒ«ãƒ¼ãƒ—ã‚’å‡¦ç†
        groups = [
            (lora_folder_path_1, include_subfolders_1, unique_by_filename_1, model_strength_1, clip_strength_1, num_loras_1, "Group 1"),
            (lora_folder_path_2, include_subfolders_2, unique_by_filename_2, model_strength_2, clip_strength_2, num_loras_2, "Group 2"),
            (lora_folder_path_3, include_subfolders_3, unique_by_filename_3, model_strength_3, clip_strength_3, num_loras_3, "Group 3"),
        ]
        
        for folder_path, include_subs, unique_by_name, model_str, clip_str, num, group_name in groups:
            # ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ãŒç©ºã€ã¾ãŸã¯num_lorasãŒ0ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if not folder_path.strip() or num == 0:
                print(f"[RandomLoRALoader] {group_name}: ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ•ã‚©ãƒ«ãƒ€æœªæŒ‡å®šã¾ãŸã¯num=0ï¼‰")
                continue
            
            # LoRAãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            lora_files = self._find_lora_files(folder_path, include_subs)
            
            if not lora_files:
                print(f"[RandomLoRALoader] {group_name}: LoRAãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                continue
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åã§ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–ï¼ˆé‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«åã‚’é™¤å¤–ï¼‰
            if unique_by_name:
                lora_files = self._unique_by_filename(lora_files, group_name)
                if not lora_files:
                    print(f"[RandomLoRALoader] {group_name}: ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–å¾Œã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
                    continue
            
            # ãƒ©ãƒ³ãƒ€ãƒ ã«LoRAã‚’é¸æŠï¼ˆå…¨ã‚°ãƒ«ãƒ¼ãƒ—å…±é€šã®seedã‚’ä½¿ç”¨ï¼‰
            selected_loras = self._select_random_loras(lora_files, num, seed)
            
            print(f"[RandomLoRALoader] {group_name}: {len(selected_loras)}å€‹ã®LoRAã‚’é¸æŠ")
            
            # å„LoRAã‚’é †æ¬¡é©ç”¨
            for lora_path in selected_loras:
                lora_name = os.path.splitext(os.path.basename(lora_path))[0]
                
                # å¼·åº¦æ–‡å­—åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ç¯„å›²å¯¾å¿œï¼‰
                actual_model_str = self._parse_strength(model_str)
                actual_clip_str = self._parse_strength(clip_str)
                
                # LoRAé©ç”¨ãƒ­ã‚°ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã¨å¼·åº¦ã‚’è¡¨ç¤ºï¼‰
                print(f"[RandomLoRALoader]   â†’ {lora_name} (MODEL:{actual_model_str}, CLIP:{actual_clip_str})")
                
                # LoRAã‚’MODELã¨CLIPã«é©ç”¨
                model, clip = self._load_lora(model, clip, lora_path, actual_model_str, actual_clip_str)
                
                # ãƒˆãƒªã‚¬ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—ï¼ˆã‚½ãƒ¼ã‚¹ã«å¿œã˜ã¦å‡¦ç†ã‚’åˆ†å²ï¼‰
                if trigger_word_source == "json_combined":
                    trigger_words = self._get_trigger_words_combined(lora_path)
                    all_positive_parts.append(trigger_words)
                    trigger_display = trigger_words
                
                elif trigger_word_source == "json_random":
                    trigger_words = self._get_trigger_words_random(lora_path)
                    all_positive_parts.append(trigger_words)
                    trigger_display = trigger_words
                
                elif trigger_word_source == "json_sample_prompt":
                    positive_prompt, negative_prompt = self._get_sample_prompt_from_json(lora_path)
                    all_positive_parts.append(positive_prompt)
                    all_negative_parts.append(negative_prompt)
                    trigger_display = positive_prompt
                
                elif trigger_word_source == "metadata":
                    trigger_words = self._get_trigger_words_from_embedded(lora_path)
                    all_positive_parts.append(trigger_words)
                    trigger_display = trigger_words
                
                # ãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›ã«è¿½åŠ ï¼ˆæœ«å°¾ã«ã‚«ãƒ³ãƒã‚’ä»˜ã‘ã‚‹ï¼‰
                lora_notation = f"<lora:{lora_name}:{actual_model_str}:{actual_clip_str}>"
                all_text_parts.append(f"{lora_notation}, {trigger_display},")
                
                # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒã‚’èª­ã¿è¾¼ã¿
                preview = self._load_preview_image_as_tensor(lora_path)
                if preview is not None:
                    preview_images.append(preview)
        
        # ãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›ã‚’çµåˆï¼ˆè¿½åŠ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…ˆé ­ã«é…ç½®ã€æœ«å°¾ã«ã‚«ãƒ³ãƒã‚’ä»˜ã‘ã‚‹ï¼‰
        if additional_prompt_positive.strip():
            # è¿½åŠ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æœ«å°¾ã«ã‚«ãƒ³ãƒãŒãªã‘ã‚Œã°è¿½åŠ 
            additional_with_comma = additional_prompt_positive.strip()
            if not additional_with_comma.endswith(','):
                additional_with_comma += ','
            if all_text_parts:
                # LoRAãŒã‚ã‚‹å ´åˆ: è¿½åŠ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ + LoRAæƒ…å ±
                positive_text_output = additional_with_comma + "\n" + "\n".join(all_text_parts)
            else:
                # LoRAãŒãªã„å ´åˆ: è¿½åŠ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ï¼ˆæœ«å°¾ã‚«ãƒ³ãƒãªã—ï¼‰
                positive_text_output = additional_prompt_positive.strip()
        else:
            # è¿½åŠ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãªã—
            if all_text_parts:
                # LoRAã®ã¿
                positive_text_output = "\n".join(all_text_parts)
            else:
                # ä½•ã‚‚ãªã„
                positive_text_output = ""
        
        # negativeãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›
        # 1. json_sample_promptã‹ã‚‰ã®negative
        sample_negative = ", ".join([n for n in all_negative_parts if n])
        # 2. additional_prompt_negativeã¨çµåˆ
        negative_parts = []
        if additional_prompt_negative.strip():
            negative_parts.append(additional_prompt_negative.strip())
        if sample_negative:
            negative_parts.append(sample_negative)
        negative_text_output = ", ".join(negative_parts)
        
        # positiveãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çµåˆã—ã¦CONDITIONINGã‚’ç”Ÿæˆï¼ˆè¿½åŠ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å«ã‚ã‚‹ï¼‰
        final_positive_parts = []
        if additional_prompt_positive.strip():
            # LoRAæ§‹æ–‡ã‚’å‰Šé™¤ã—ã¦ã‚¯ãƒªãƒ¼ãƒ³ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã™ã‚‹
            cleaned_prompt = self._remove_lora_syntax(additional_prompt_positive.strip())
            if cleaned_prompt:  # å‰Šé™¤å¾Œã«ç©ºã§ãªã‘ã‚Œã°è¿½åŠ 
                final_positive_parts.append(cleaned_prompt)
        final_positive_parts.extend([p for p in all_positive_parts if p])
        positive_text = ", ".join(final_positive_parts)
        positive_conditioning = self._encode_prompt(
            clip, positive_text, token_normalization, weight_interpretation
        )
        
        # negativeãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çµåˆã—ã¦CONDITIONINGã‚’ç”Ÿæˆ
        final_negative_parts = []
        if additional_prompt_negative.strip():
            cleaned_negative = self._remove_lora_syntax(additional_prompt_negative.strip())
            if cleaned_negative:
                final_negative_parts.append(cleaned_negative)
        final_negative_parts.extend([n for n in all_negative_parts if n])
        negative_text = ", ".join(final_negative_parts)
        negative_conditioning = self._encode_prompt(
            clip, negative_text, token_normalization, weight_interpretation
        )
        
        total_loras = len(all_text_parts)
        if total_loras > 0:
            print(f"[RandomLoRALoader] é©ç”¨å®Œäº†: åˆè¨ˆ{total_loras}å€‹ã®LoRA")
        elif additional_prompt_positive.strip():
            print(f"[RandomLoRALoader] é©ç”¨å®Œäº†: LoRAãªã—ã€è¿½åŠ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ä½¿ç”¨")
        else:
            print(f"[RandomLoRALoader] é©ç”¨å®Œäº†: LoRAãªã—ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãªã—")
        
        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒãƒãƒƒãƒç”Ÿæˆ
        preview_batch = self._generate_preview_batch(preview_images)
        
        return (model, clip, positive_text_output, negative_text_output, positive_conditioning, negative_conditioning, preview_batch)
